# sdgp-ml

Welcome to the sdgp-ml repository!

This repository contains notebooks and resources related to the Software Development Group Project (SDGP) machine learning component. Specifically, it includes two notebooks used for creating a dataset and fine-tuning a Mistral-7B-v0.1-Instruct model. Additionally, the repository houses the dataset utilized in fine-tuning the model.

## Requirements

To run the fine-tuning notebook successfully, ensure that your machine meets the following requirements:

- At least 24 GB VRAM
- Latest NVIDIA drivers installed
- CUDA version 12.1 or higher

## Fine-Tuned Model

We've fine-tuned the Mistral-7B-v0.1-Instruct model using our dataset. You can access the fine-tuned model through [this link](https://huggingface.co/vpgits/Mistral-7B-v0.1-qagen-v2.1-AWQ).

## Disclaimer

**Disclaimer:** This project is solely for educational purposes and research within the Semantic Digital Governance Project.

## References and Resources

To further explore related topics and resources, you may find the following links useful:

- [Tuning-the-Finetuning](https://github.com/avisoori-databricks/Tuning-the-Finetuning)
- [Mistral Mastery: Fine-Tuning & Fast Inference Guide](https://medium.com/@parikshitsaikia1619/mistral-mastery-fine-tuning-fast-inference-guide-62e163198b06)
- [4-bit Transformers with Hugging Face](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
- [Transformers for Legal Language](https://huggingface.co/docs/trl/en/sft_trainer)
- [AutoAWQ](https://github.com/casper-hansen/AutoAWQ)

Feel free to explore these references and the code.
